---
title: "Руководство по контекстному окну"
description: "Понимание и управление контекстными окнами AI моделей"
---

<Note>
Это документация для Careti. Соответствует версии Careti v3.38.1 (мерж). Если есть политика, специфичная для Careti (ограничение контекста по модели поддержки/блокировки, аутентификация/маршрутизация), это будет указано в тексте с помощью `<Note>`.
</Note>

## Что такое контекстное окно?

Контекстное окно - это максимальный объем текста, который AI модель может обработать за один раз. Представьте это как "рабочую память" модели - она определяет, какой объем вашей беседы и кода модель может учитывать при генерации ответов.

<Note>
**Ключевой момент**: Большие контекстные окна позволяют модели понимать больший объем вашего кода одновременно, но могут увеличить затраты и время ответа.
</Note>

## Размеры контекстных окон

### Краткий справочник

| Размер | Tokens | Примерное количество слов | Вариант использования |
|------|--------|------------------|----------|
| **Маленький** | 8K-32K | 6,000-24,000 | Единичные файлы, быстрые исправления |
| **Средний** | 128K | ~96,000 | Большинство проектов кодирования |
| **Большой** | 200K | ~150,000 | Сложные кодовые базы |
| **Очень большой** | 400K+ | ~300,000+ | Целые приложения |
| **Огромный** | 1M+ | ~750,000+ | Анализ нескольких проектов |

### Контекстные окна моделей

| Модель | Контекстное окно | Эффективное окно* | Примечания |
|-------|---------------|------------------|-------|
| **Claude Sonnet 4.5** | 1M tokens | ~500K tokens | Лучшее качество при большом контексте |
| **GPT-5** | 400K tokens | ~300K tokens | Три режима влияют на производительность |
| **Gemini 2.5 Pro** | 1M+ tokens | ~600K tokens | Отлично подходит для документов |
| **DeepSeek V3** | 128K tokens | ~100K tokens | Оптимально для большинства задач |
| **Qwen3 Coder** | 256K tokens | ~200K tokens | Хороший баланс |

*Эффективное окно - это место, где модель поддерживает высокое качество

## Эффективное управление контекстом

### Что учитывается в контексте

1. **Ваша текущая беседа** - Все сообщения в чате
2. **Содержимое файлов** - Любые файлы, которыми вы поделились или которые Careti прочитал
3. **Вывод инструментов** - Результаты выполненных команд
4. **Системные подсказки** - Инструкции Careti (минимальное влияние)

### Стратегии оптимизации

#### 1. Начинайте с чистого листа для новых функций
```
/new - Создает новую задачу с чистым контекстом
```
Преимущества:
- Максимальный доступный контекст
- Отсутствие нерелевантной истории
- Лучшая фокусировка модели

#### 2. Используйте @ Mentions стратегически
Вместо включения целых файлов:
- `@filename.ts` - Включайте только при необходимости
- Используйте поиск вместо чтения больших файлов
- Ссылайтесь на конкретные функции, а не на целые файлы

#### 3. Включите Auto-compact
Careti может автоматически суммировать длинные разговоры:
- Settings → Features → Auto-compact
- Сохраняет важный контекст
- Уменьшает использование tokens

## Предупреждения о контекстном окне

### Признаки достижения лимитов

| Предупреждающий знак | Что это значит | Решение |
|-------------|---------------|----------|
| **"Context window exceeded"** | Достигнут жесткий предел | Начните новую задачу или включите auto-compact |
| **Более медленные ответы** | Модель испытывает трудности с контекстом | Уменьшите количество включенных файлов |
| **Повторяющиеся предложения** | Фрагментация контекста | Суммируйте и начните с чистого листа |
| **Отсутствуют последние изменения** | Переполнение контекста | Используйте checkpoints для отслеживания изменений |

### Рекомендации в зависимости от размера проекта

#### Маленькие проекты (< 50 файлов)
- Любая модель работает хорошо
- Включайте релевантные файлы свободно
- Никакой специальной оптимизации не требуется

#### Средние проекты (50-500 файлов)
- Используйте модели с контекстом 128K+
- Включайте только рабочий набор файлов
- Очищайте контекст между функциями

#### Большие проекты (500+ файлов)
- Используйте модели с контекстом 200K+
- Сосредоточьтесь на конкретных модулях
- Используйте поиск вместо чтения многих файлов
- Разбейте работу на более мелкие задачи

## Расширенное управление контекстом

### Оптимизация режима Plan/Act

Используйте режим Plan/Act для лучшего использования контекста:
- **Plan Mode**: Используйте меньший контекст для обсуждения
- **Act Mode**: Включайте необходимые файлы для реализации

Конфигурация:
```
Plan Mode: DeepSeek V3 (128K) - Более дешевое планирование
Act Mode: Claude Sonnet (1M) - Максимальный контекст для кодирования
```

### Стратегии сокращения контекста

1. **Временное сокращение**: Удалите старые части разговора
2. **Семантическое сокращение**: Сохраняйте только релевантные разделы кода
3. **Иерархическое сокращение**: Поддерживайте структуру высокого уровня, сокращайте детали

### Советы по подсчету tokens

#### Грубые оценки
- **1 token ≈ 0.75 слов**
- **1 token ≈ 4 символа**
- **100 строк кода ≈ 500-1000 tokens**

#### Рекомендации по размеру файлов
| Тип файла | Tokens на KB |
|-----------|---------------|
| **Code** | ~250-400 |
| **JSON** | ~300-500 |
| **Markdown** | ~200-300 |
| **Plain text** | ~200-250 |

## Context Window FAQ

### В: Почему ответы становятся хуже при очень длинных разговорах?
**О:** Модели могут терять фокус при слишком большом количестве контекста. "Эффективное окно" обычно составляет 50-70% от заявленного лимита.

### В: Следует ли использовать самое большое доступное контекстное окно?
**О:** Не всегда. Большие контексты увеличивают затраты и могут снизить качество ответа. Сопоставьте контекст с размером вашей задачи.

### В: Как узнать, сколько контекста я использую?
**О:** Careti показывает использование tokens в интерфейсе. Следите за тем, чтобы индикатор контекста приближался к пределам.

### В: Что происходит, когда я превышаю предел контекста?
**О:** Careti будет либо:
- Автоматически уплотнять разговор (если включено)
- Показывать ошибку и предлагать начать новую задачу
- Усекать старые сообщения (с предупреждением)

## Рекомендации по вариантам использования

| Вариант использования | Рекомендуемый контекст | Предложение модели |
|----------|-------------------|------------------|
| **Быстрые исправления** | 32K-128K | DeepSeek V3 |
| **Разработка функций** | 128K-200K | Qwen3 Coder |
| **Большой рефакторинг** | 400K+ | Claude Sonnet 4.5 |
| **Code review** | 200K-400K | GPT-5 |
| **Документация** | 128K | Любая бюджетная модель |
