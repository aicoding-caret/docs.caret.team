---
title: "LM Studio"
description: "Краткое руководство по настройке LM Studio для локального запуска AI-моделей с помощью Careti."
---

<Note>
Это документация для Careti. Она основана на версии Careti v3.38.1. Любые специфические политики Careti (поддерживаемые локальные среды выполнения, аутентификация/маршрутизация, ограничения моделей) будут отмечены тегом `<Note>` в тексте.
</Note>

## Настройка LM Studio для Careti

Запускайте AI-модели локально, используя LM Studio совместно с Careti.

### Предварительные требования

-   Компьютер на базе Windows, macOS или Linux с поддержкой AVX2
-   Установленный Careti в VS Code

### Этапы настройки

#### 1. Установка LM Studio

-   Перейдите на сайт [lmstudio.ai](https://lmstudio.ai)
-   Загрузите и установите версию для вашей операционной системы

<Frame>
	<img src="https://storage.googleapis.com/cline_public_images/docs/assets/image%20(7).png" alt="LM Studio download page" />
</Frame>

#### 2. Запуск LM Studio

-   Откройте установленное приложение
-   Слева вы увидите четыре вкладки: **Chat**, **Developer** (где вы будете запускать сервер), **My Models** (где хранятся ваши загруженные модели), **Discover** (поиск новых моделей)

<Frame>
	<img
		src="https://storage.googleapis.com/cline_public_images/docs/assets/image%20(10).png"
		alt="LM Studio interface overview"
	/>
</Frame>

#### 3. Загрузка модели

-   Изучите страницу «Discover»
-   Выберите и загрузите подходящую модель
-   Дождитесь завершения загрузки

<Frame>
	<img
		src="https://storage.googleapis.com/cline_public_images/docs/assets/lm-studio-download-model.gif"
		alt="Downloading a model in LM Studio"
	/>
</Frame>

#### 4. Запуск сервера

-   Перейдите на вкладку «Developer»
-   Переключите тумблер сервера в положение «Running»
-   Примечание: Сервер будет запущен по адресу `http://localhost:1234`

<Frame>
	<img
		src="https://storage.googleapis.com/cline_public_images/docs/assets/lm-studio-starting-server.gif"
		alt="Starting the LM Studio server"
	/>
</Frame>

#### 5. Настройка Careti

1. Откройте VS Code
2. Нажмите на иконку настроек Careti
3. Выберите «LM Studio» в качестве API provider
4. Выберите свою модель из списка доступных вариантов

<Frame>
	<img
		src="https://storage.googleapis.com/cline_public_images/docs/assets/lm-studio-select-model-caret.gif"
		alt="Configuring Careti with LM Studio"
	/>
</Frame>

### Рекомендуемая модель и настройки

Для наилучшей работы с Careti используйте **Qwen3 Coder 30B A3B Instruct**. Эта модель обеспечивает высокую производительность при написании кода и надежную работу с инструментами.

#### Критические настройки

После загрузки модели на вкладке Developer настройте следующие параметры:

1. **Context Length**: Установите значение 262,144 (максимум для этой модели)
2. **KV Cache Quantization**: Оставьте флажок снятым (важно для стабильной производительности)
3. **Flash Attention**: Включите, если доступно (повышает производительность)

#### Руководство по квантованию

Выбирайте квантование в зависимости от объема вашей RAM:

- **32GB RAM**: Используйте 4-bit квантование (~17GB для загрузки)
- **64GB RAM**: Используйте 8-bit квантование (~32GB для загрузки) для лучшего качества
- **128GB+ RAM**: Рассмотрите возможность использования полной точности (full precision) или более крупных моделей

#### Формат моделей

- **Mac (Apple Silicon)**: Используйте формат MLX для оптимизированной производительности
- **Windows/Linux**: Используйте формат GGUF

### Включение Compact Prompts

Для оптимальной работы с локальными моделями включите компактные промпты в настройках Careti. Это уменьшит размер промпта на 90%, сохраняя при этом основную функциональность.

Перейдите в Careti Settings → Features → Use Compact Prompt и включите эту опцию.

### Важные примечания

-   Запускайте LM Studio перед использованием Careti
-   Оставляйте LM Studio работающим в фоновом режиме
-   Первая загрузка модели может занять несколько минут в зависимости от размера
-   После загрузки модели хранятся локально

### Устранение неполадок

1. Если Careti не может подключиться к LM Studio:
2. Убедитесь, что сервер LM Studio запущен (проверьте вкладку Developer)
3. Убедитесь, что модель загружена
4. Проверьте, соответствует ли ваша система аппаратным требованиям