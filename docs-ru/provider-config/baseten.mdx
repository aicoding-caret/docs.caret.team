---
title: "Baseten"
description: "Узнайте, как настроить и использовать Baseten Model APIs в Caret. Получите доступ к передовым open-source моделям с производительностью корпоративного уровня, надежностью и конкурентоспособными ценами."
---

<Note>
Это справочный документ для Caret. Он соответствует версии Caret v3.38.1. Если существуют специфические политики Caret (разрешенные/заблокированные модели, региональные ограничения, аутентификация/маршрутизация), они будут помечены тегом `<Note>` в тексте.
</Note>

<Note>
Улучшение Provider Setup: В соответствии с `caret-docs/features/f09-enhanced-provider-setup.md`, в Caret может быть улучшена проверка настроек провайдера и UX. Обратите внимание, что список разрешенных/заблокированных моделей может меняться в зависимости от политик аккаунта/организации или применения Caret Router.
</Note>

Baseten предоставляет API передовых моделей по запросу, разработанные для использования в продакшене, а не только для экспериментов. Построенные на стеке Baseten Inference Stack, эти API обеспечивают производительность и надежность корпоративного уровня с оптимизированным выводом (inference) для ведущих open-source моделей от OpenAI, DeepSeek, Meta, Moonshot AI и Alibaba Cloud.

**Веб-сайт:** [https://www.baseten.co/products/model-apis/](https://www.baseten.co/products/model-apis/)

### Получение API Key

1.  **Регистрация/Вход:** Перейдите на [Baseten](https://www.baseten.co/) и создайте аккаунт или войдите в существующий.
2.  **Переход к API Keys:** В панели управления перейдите в раздел API Keys.
3.  **Создание ключа:** Сгенерируйте новый API key. Дайте ему понятное название (например, "Caret").
4.  **Копирование ключа:** Немедленно скопируйте API key и сохраните его в надежном месте.

### Поддерживаемые модели

Caret поддерживает все актуальные модели в рамках Baseten Model APIs, включая:
Актуальную информацию о ценах можно найти здесь: https://www.baseten.co/products/model-apis/
Примечание: API моделей Kimi K2 0711, Llama 4 Maverick и Llama 4 Scout были объявлены устаревшими 8 октября в 17:00 PT.
https://www.baseten.co/resources/changelog/model-api-deprecation-notice-kimi-k2-0711-scout-maverick/

-   `zai-org/GLM-4.6` (Z AI) — передовая открытая модель с расширенными возможностями агентов, рассуждения и написания кода от Z AI (контекст 200k) $0.60/$2.20 за 1M токенов
-   `moonshotai/Kimi-K2-Instruct-0905` (Moonshot AI) — сентябрьское обновление с расширенными возможностями (контекст 262K) — $0.60/$2.50 за 1M токенов
-   `openai/gpt-oss-120b` (OpenAI) — 120B MoE с сильными способностями к рассуждению (контекст 128K) — $0.10/$0.50 за 1M токенов
-   `Qwen/Qwen3-Coder-480B-A35B-Instruct` — продвинутое написание кода и рассуждение (контекст 262K) — $0.38/$1.53 за 1M токенов
-   `Qwen/Qwen3-235B-A22B-Instruct-2507` — эксперт в математике и рассуждениях (контекст 262K) — $0.22/$0.80 за 1M токенов
-   `deepseek-ai/DeepSeek-R1` — модель для рассуждений первого поколения от DeepSeek (контекст 163K) — $2.55/$5.95 за 1M токенов
-   `deepseek-ai/DeepSeek-R1-0528` — последняя ревизия модели для рассуждений DeepSeek (контекст 163K) — $2.55/$5.95 за 1M токенов
-   `deepseek-ai/DeepSeek-V3.1` — гибридное рассуждение с продвинутым вызовом инструментов (контекст 163K) — $0.50/$1.50 за 1M токенов
-   `deepseek-ai/DeepSeek-V3-0324` — быстрая модель общего назначения с улучшенным рассуждением (контекст 163K) — $0.77/$0.77 за 1M токенов

### Настройка в Caret

1.  **Открыть настройки Caret:** Нажмите на иконку шестеренки (⚙️) в панели Caret.
2.  **Выбрать провайдера:** Выберите "Baseten" в выпадающем списке "API Provider".
3.  **Ввести API Key:** Вставьте ваш Baseten API key в поле "Baseten API Key".
4.  **Выбрать модель:** Выберите нужную модель в выпадающем списке "Model".

### Архитектура, ориентированная на продакшен

Baseten Model APIs созданы для использования в продакшен-средах и обладают рядом ключевых преимуществ:

#### Надежность корпоративного уровня
- **Доступность «четыре девятки»** (99.99%) благодаря активно-активному резервированию
- **Облачно-независимое мультикластерное автоскейлирование** для стабильной доступности
- **Сертификация SOC 2 Type II** и **соответствие HIPAA** для обеспечения требований безопасности

#### Оптимизированная производительность
- **Предварительно оптимизированные модели**, поставляемые со стеком Baseten Inference Stack
- **GPU последнего поколения** в мультиоблачной инфраструктуре
- **Сверхбыстрый вывод (inference)**, оптимизированный «снизу вверх» для рабочих нагрузок продакшена

#### Экономическая эффективность
- **В 5–10 раз дешевле**, чем закрытые альтернативы
- **Оптимизированная мультиоблачная инфраструктура** для эффективного использования ресурсов
- **Прозрачное ценообразование** без скрытых затрат или неожиданных ограничений (rate limits)

#### Опыт разработчика
- **OpenAI-совместимый API** — миграция путем замены одного URL
- **Прямая замена (drop-in replacement)** закрытых моделей с полной наблюдаемостью (observability)
- **Бесшовное масштабирование** от Model APIs к выделенным развертываниям

### Особенности

#### Вызов функций и использование инструментов (Function Calling & Tool Use)
Все модели Baseten поддерживают структурированные выходные данные, вызов функций и использование инструментов как часть Baseten Inference Stack, что делает их идеальными для агентских приложений.

#### Возможности рассуждения (Reasoning Capabilities)
Модели DeepSeek предлагают улучшенное рассуждение с пошаговыми процессами мышления, сохраняя при этом готовую к продакшену производительность.

#### Поддержка длинного контекста
- **До 1 миллиона токенов** для моделей Llama 4 (Maverick и Scout)
- **262K токенов** для моделей Qwen3
- **163K токенов** для моделей DeepSeek
- **Идеально подходит для репозиториев кода** и сложных многоходовых диалогов

#### Оптимизация квантования
Модели развертываются с использованием передовых методов квантования (fp4, fp8, fp16) для обеспечения оптимальной производительности при сохранении качества.

### Миграция от других провайдеров

Совместимость Baseten с OpenAI делает миграцию простой:

**С OpenAI:**
- Замените `api.openai.com` на `inference.baseten.co/v1`
- Сохраните существующие форматы запросов и ответов
- Получите значительную экономию средств

**С других провайдеров:**
- Используйте стандартный формат OpenAI SDK
- Сохраните существующие стратегии промптинга
- Получите доступ к новейшим open-source моделям

### Советы и примечания

-   **Выбор модели:** Выбирайте модели в зависимости от вашей конкретной задачи: модели для рассуждений — для сложных задач, модели для кодинга — для разработки, и флагманские модели — для приложений общего назначения.
-   **Оптимизация затрат:** Baseten предлагает одни из самых конкурентоспособных цен на рынке, особенно для open-source моделей.
-   **Окна контекста:** Используйте преимущества больших окон контекста (до 1М токенов) для включения объемных кодовых баз и документации.
-   **Готовность к корпоративному использованию:** Baseten разработан для использования в продакшене с безопасностью корпоративного уровня, соответствием стандартам и надежностью.
-   **Динамическое обновление моделей:** Caret автоматически подгружает актуальный список моделей из Baseten, обеспечивая доступ к новинкам сразу после их релиза.
-   **Multi-Cloud Capacity Management (MCM):** Мультиоблачная инфраструктура Baseten обеспечивает высокую доступность и низкую задержку по всему миру.
-   **Поддержка:** Baseten предоставляет специализированную поддержку для продакшен-развертываний и может работать с вами над выделенными ресурсами по мере масштабирования.

### Информация о ценах

Текущие цены очень конкурентоспособны и прозрачны. Для получения самой актуальной информации о ценах посетите [страницу Baseten Model APIs](https://www.baseten.co/products/model-apis/). Цены обычно варьируются от $0.10 до $6.00 за миллион токенов, что делает Baseten значительно более экономичным решением, чем многие альтернативы с закрытыми моделями, при этом обеспечивая доступ к самым современным open-source моделям.