---
title: "Requesty"
description: "Узнайте, как использовать Requesty с Careti для доступа и оптимизации более 150 больших языковых моделей."
---

Careti поддерживает доступ к моделям через AI-платформу [Requesty](https://www.requesty.ai/). Requesty предоставляет простой и оптимизированный API для взаимодействия с более чем 150 большими языковыми моделями (LLM).

**Веб-сайт:** [https://www.requesty.ai/](https://www.requesty.ai/)

### Получение API Key

1.  **Регистрация/Вход:** Перейдите на [веб-сайт Requesty](https://www.requesty.ai/) и создайте учетную запись или войдите в систему.
2.  **Получение API Key:** Вы можете получить API Key в разделе [API Management](https://app.requesty.ai/api-keys) вашей панели управления Requesty.

### Поддерживаемые модели

Requesty предоставляет доступ к широкому спектру моделей. Careti автоматически загрузит актуальный список доступных моделей. Вы можете просмотреть полный список доступных моделей на странице [Model List](https://app.requesty.ai/router/list).

### Настройка в Careti

1.  **Откройте настройки Careti:** Нажмите на иконку настроек (⚙️) на панели Careti.
2.  **Выберите провайдера:** Выберите «Requesty» в выпадающем списке «API Provider».
3.  **Введите API Key:** Вставьте ваш Requesty API Key в поле «Requesty API Key».
4.  **Выберите модель:** Выберите нужную модель в выпадающем списке «Model».

### Советы и примечания

-   **Оптимизация**: Requesty предлагает ряд оптимизаций затрат «на лету» для снижения ваших расходов.
-   **Единая и упрощенная система оплаты**: Неограниченный доступ ко всем провайдерам и моделям, автоматическое пополнение баланса и многое другое через один [API Key](https://app.requesty.ai/api-keys).
-   **Отслеживание затрат**: Отслеживайте стоимость в разрезе моделей, языков программирования, измененных файлов и многого другого через [Cost dashboard](https://app.requesty.ai/cost-management) или [Requesty VS Code extension](https://marketplace.visualstudio.com/items?itemName=Requesty.requesty).
-   **Статистика и логи**: Просматривайте свою [панель статистики кодинга](https://app.requesty.ai/usage-stats) или изучайте [логи взаимодействия с LLM](https://app.requesty.ai/logs).
-   **Резервные политики (Fallback policies)**: Поддерживайте работу вашей LLM с помощью резервных политик на случай сбоев у провайдеров.
-   **Prompt Caching:** Некоторые провайдеры поддерживают кэширование промптов. [Поиск моделей с кэшированием](https://app.requesty.ai/router/list).

### Полезные ресурсы

-   [YouTube-канал Requesty](https://www.youtube.com/@requestyAI)
-   [Requesty Discord](https://requesty.ai/discord)