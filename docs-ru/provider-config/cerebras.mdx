---
title: "Cerebras"
description: "Узнайте, как настроить и использовать сверхбыстрый инференс Cerebras в Caret. Оцените скорость до 2 600 токенов в секунду благодаря архитектуре чипов wafer-scale и моделям рассуждения в реальном времени."
---

<Note>
Это справочный документ для Caret. Он основан на версии Caret v3.38.1. Любые специфические политики Caret (разрешенные/заблокированные модели, региональные ограничения, аутентификация/маршрутизация) помечаются в тексте тегом `<Note>`.
</Note>

<Note>
Улучшенная настройка провайдера: согласно `caret-docs/features/f09-enhanced-provider-setup.md`, в Caret может быть улучшена проверка настроек провайдера и UX. Обратите внимание, что список разрешенных или заблокированных моделей может меняться в зависимости от политик аккаунта/организации или использования Caret Router.
</Note>

Cerebras обеспечивает самый быстрый в мире AI инференс благодаря своей революционной архитектуре чипов wafer-scale. В отличие от традиционных GPU, которые перемещают веса моделей из внешней памяти, Cerebras хранит целые модели прямо на чипе, устраняя узкие места пропускной способности и достигая скорости до 2 600 токенов в секунду — зачастую в 20 раз быстрее, чем GPU.

**Website:** [https://cloud.cerebras.ai/](https://cloud.cerebras.ai/)

### Getting an API Key

1.  **Регистрация/Вход:** Перейдите в [Cerebras Cloud](https://cloud.cerebras.ai/) и создайте аккаунт или войдите в систему.
2.  **Перейдите к API Keys:** Откройте раздел API-ключей в вашей панели управления.
3.  **Создайте ключ:** Сгенерируйте новый API-ключ. Дайте ему описательное имя (например, «Caret»).
4.  **Скопируйте ключ:** Немедленно скопируйте API-ключ. Храните его в безопасном месте.

### Supported Models

Caret поддерживает следующие модели Cerebras:

-   `zai-glm-4.6` — Интеллектуальная модель общего назначения со скоростью 1 500 токенов/с
-   `qwen-3-235b-a22b-instruct-2507` — Продвинутая модель для следования инструкциям
-   `qwen-3-235b-a22b-thinking-2507` — Модель для рассуждений (reasoning) с пошаговым мышлением
-   `llama-3.3-70b` — Модель Meta Llama 3.3, оптимизированная для скорости
-   `qwen-3-32b` — Компактная, но мощная модель для общих задач

### Configuration in Caret

1.  **Откройте настройки Caret:** Нажмите на иконку настроек (⚙️) на панели Caret.
2.  **Выберите провайдера:** Выберите «Cerebras» в выпадающем списке «API Provider».
3.  **Введите API-ключ:** Вставьте ваш API-ключ Cerebras в поле «Cerebras API Key».
4.  **Выберите модель:** Выберите нужную модель в выпадающем списке «Model».
5.  **(Опционально) Custom Base URL:** Большинству пользователей не потребуется изменять этот параметр.

### Преимущество Wafer-Scale архитектуры Cerebras

Cerebras фундаментально переосмыслили архитектуру аппаратного обеспечения для AI, чтобы решить проблему скорости инференса:

#### Wafer-Scale Architecture
Традиционные GPU используют отдельные чипы для вычислений и памяти, что заставляет их постоянно перемещать веса моделей туда и обратно. Cerebras создали самый большой в мире AI-чип — wafer-scale engine, который хранит целые модели прямо на кристалле. Никакой внешней памяти, никаких ограничений пропускной способности, никакого ожидания.

#### Революционная скорость
- **До 2 600 токенов в секунду** — зачастую в 20 раз быстрее, чем GPU
- **Рассуждения за одну секунду** — то, что раньше занимало минуты, теперь происходит мгновенно
- **Приложения реального времени** — модели рассуждения становятся практичными для интерактивного использования
- **Никаких лимитов пропускной способности** — хранение всей модели на чипе устраняет узкие места памяти

#### Закон масштабирования Cerebras (The Cerebras Scaling Law)
Cerebras обнаружили, что **более быстрый инференс делает AI умнее**. Современные модели рассуждения генерируют тысячи токенов в качестве «внутреннего монолога» перед ответом. На традиционном оборудовании это занимает слишком много времени для использования в реальном времени. Cerebras делает модели рассуждения достаточно быстрыми для повседневных приложений.

#### Качество без компромиссов
В отличие от других методов оптимизации скорости, которые жертвуют точностью, Cerebras сохраняет полное качество модели, обеспечивая при этом беспрецедентную скорость. Вы получаете интеллект передовых моделей с отзывчивостью легковесных решений.

Узнайте больше о технологиях Cerebras в их блоге:
- [The Cerebras Scaling Law: Faster Inference Is Smarter AI](https://www.cerebras.ai/blog/the-cerebras-scaling-law-faster-inference-is-smarter-ai)
- [Introducing Cerebras Code](https://www.cerebras.ai/blog/introducing-cerebras-code)

### Тарифные планы Cerebras Code

Cerebras предлагает специализированные тарифные планы для разработчиков:

#### Code Pro ($50/месяц)
- Доступ к Qwen3-Coder с быстрым автодополнением в большом контексте
- До 24 миллионов токенов в день
- Идеально подходит для независимых разработчиков и пет-проектов
- 3–4 часа непрерывного написания кода в день

#### Code Max ($200/месяц)
- Поддержка интенсивных рабочих процессов программирования
- До 120 миллионов токенов в день
- Идеально подходит для профессиональной разработки и мультиагентных систем
- Без еженедельных лимитов, без привязки к конкретной IDE

### Особые возможности

#### Бесплатный уровень (Free Tier)
Модель `qwen-3-coder-480b-free` предоставляет доступ к высокопроизводительному инференсу бесплатно — уникальное предложение среди провайдеров, ориентированных на скорость.

#### Рассуждения в реальном времени (Real-Time Reasoning)
Модели рассуждения, такие как `qwen-3-235b-a22b-thinking-2507`, могут выполнять сложные многоэтапные рассуждения менее чем за секунду, что делает их практичными для интерактивных процессов разработки.

#### Специализация на коде
Модели Qwen3-Coder специально оптимизированы для задач программирования, демонстрируя производительность, сравнимую с Claude Sonnet 4 и GPT-4.1 в бенчмарках по кодингу.

#### Отсутствие привязки к IDE
Работает с любым инструментом, совместимым с OpenAI — Cursor, Continue.dev, Caret или любым другим редактором, поддерживающим эндпоинты OpenAI.

### Советы и примечания

-   **Преимущество в скорости:** Cerebras отлично справляется с тем, чтобы сделать модели рассуждения практичными для использования в реальном времени. Идеально подходит для агентных рабочих процессов, требующих множества вызовов LLM.
-   **Бесплатный уровень:** Начните с бесплатной модели, чтобы оценить скорость Cerebras, прежде чем переходить на платные тарифы.
-   **Окна контекста:** Модели поддерживают окна контекста от 64K до 128K токенов для работы с объемным кодом.
-   **Лимиты запросов:** Щедрые лимиты запросов (Rate Limits), разработанные для процессов разработки. Проверьте текущие ограничения в вашей панели управления.
-   **Цены:** Конкурентоспособная стоимость с существенным преимуществом в скорости. Посетите [Cerebras Cloud](https://cloud.cerebras.ai/) для ознакомления с актуальными тарифами.
-   **Приложения реального времени:** Идеально подходит для задач, где важна скорость ответа AI — генерация кода, отладка и интерактивная разработка.