---
title: "Vercel AI Gateway"
description: "Используйте Vercel AI Gateway в Caret для доступа к более чем 100 моделям через одну конечную точку с маршрутизацией, повторными попытками и мониторингом затрат."
---

Vercel AI Gateway предоставляет единый API для доступа к моделям от множества провайдеров. Вы переключаетесь по model id без замены SDK или управления множеством ключей. Caret интегрируется напрямую, поэтому вы можете выбрать модель Gateway в выпадающем списке, использовать ее как любого другого провайдера и видеть использование токенов и кэша в потоке.

Полезные ссылки:
- Панель управления команды: https://vercel.com/d?to=%2F%5Bteam%5D%2F%7E%2Fai
- Каталог моделей: https://vercel.com/ai-gateway/models
- Документация: https://vercel.com/docs/ai-gateway

## Что вы получаете

- Одна конечная точка для 100+ моделей с одним ключом
- Автоматические повторные попытки и резервные варианты (fallbacks), которые вы настраиваете в панели управления
- Мониторинг затрат с запросами по моделям, количеством токенов, использованием кэша, перцентилями задержки и стоимостью
- OpenAI-совместимый интерфейс, обеспечивающий работу существующих клиентов

## Получение API Key

1. Войдите на сайте https://vercel.com
2. Dashboard → AI Gateway → API Keys → Create key
3. Скопируйте ключ

Для получения дополнительной информации о вариантах аутентификации и OIDC см. https://vercel.com/docs/ai-gateway/authentication

## Настройка в Caret

1. Откройте настройки Caret
2. Выберите **Vercel AI Gateway** в качестве API Provider
3. Вставьте ваш Gateway API Key
4. Выберите модель из списка. Caret автоматически загружает каталог. Вы также можете вставить точный id вручную

Примечания:
- Model id часто имеют формат `provider/model`. Скопируйте точный id из каталога  
  Примеры:
  - `openai/gpt-5`
  - `anthropic/claude-sonnet-4`
  - `google/gemini-2.5-pro`
  - `groq/llama-3.1-70b`
  - `deepseek/deepseek-v3`

## Аналитика для принятия решений

<Frame>
  <img src="https://assets.vercel.com/image/upload/v1753121283/gateway-overhead-dark_zhqwwj.svg" alt="Vercel AI Gateway observability with requests by model, tokens, cache, latency, and cost." />
</Frame>

На что обратить внимание:
- Запросы по моделям — подтверждение маршрутизации и внедрения
- Токены — входящие против исходящих, включая рассуждения (reasoning), если они доступны
- Кэш — кэшированные входящие данные и токены создания кэша
- Задержка (Latency) — p75 длительности и p75 времени до первого токена (TTFT)
- Стоимость — на проект и на модель

Используйте это для:
- Сравнения исходящих токенов на запрос до и после изменения модели
- Проверки стратегии кэширования путем отслеживания чтения из кэша и создания записей
- Выявления регрессий TTFT во время экспериментов
- Приведения бюджетов в соответствие с реальным использованием

## Поддерживаемые модели

Gateway поддерживает большой и постоянно меняющийся набор моделей. Caret получает список через Gateway API и кэширует его локально. Актуальный каталог доступен по адресу https://vercel.com/ai-gateway/models

## Советы

<Tip>
Используйте отдельные ключи Gateway для разных окружений (dev, staging, prod). Это сохранит чистоту панелей управления и изолирует бюджеты.
</Tip>

<Note>
Ценообразование является сквозным по прайс-листу провайдера. При использовании своего ключа (Bring-your-own key) наценка составляет 0%. Вы по-прежнему оплачиваете услуги провайдера и комиссии за обработку.
</Note>

<Info>
Vercel не накладывает ограничения скорости (rate limits). Вышестоящие провайдеры могут их устанавливать. Новые аккаунты получают кредит в размере $5 каждые 30 дней до первого платежа.
</Info>

## Устранение неполадок

- 401 — отправляйте ключ Gateway на конечную точку Gateway, а не на URL провайдера
- 404 model — скопируйте точный id из каталога Vercel
- Slow first token — проверьте p75 TTFT в панели управления и попробуйте модель, оптимизированную для потоковой передачи
- Cost spikes — посмотрите разбивку по моделям в панели управления и ограничьте или перенаправьте трафик

## Примеры использования

- Оценка нескольких моделей — меняйте только model id в Caret и сравнивайте задержку и количество исходящих токенов
- Прогрессивное развертывание — направляйте небольшой процент трафика на новую модель в панели управления и увеличивайте нагрузку, опираясь на метрики
- Контроль бюджета — устанавливайте лимиты для отдельных проектов без изменения кода

## Ссылки

- OpenAI-Compatible setup: /russian/provider-config/openai-compatible
- Model Selection Guide: /russian/getting-started/model-selection-guide
- Understanding Context Management: /russian/getting-started/understanding-context-management