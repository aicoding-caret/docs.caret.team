---
title: "Baseten"
description: "Caret で Baseten Model APIs を設定・利用する方法を説明します。"
---

<Note>
キャレット(Caret)基準の文書です。Caret v3.38.1 マージ版に準拠し、許可/制限モデルや地域制限があれば `<Note>` で示します。
</Note>

<Note>
Provider Setup 強化: `caret-docs/features/f09-enhanced-provider-setup.md` により、プロバイダー設定の検証/UX が強化される場合があります。
</Note>

Baseten は実験用途ではなくプロダクション用途向けのフロンティアモデル API を提供します。Baseten Inference Stack により、OpenAI/DeepSeek/Meta/Moonshot/Alibaba などのオープンモデルに最適化された推論を提供します。

**Website:** [https://www.baseten.co/products/model-apis/](https://www.baseten.co/products/model-apis/)

### API キーの取得

1. **サインアップ/サインイン:** [Baseten](https://www.baseten.co/) でアカウントを作成/ログイン
2. **API Keys へ移動**
3. **キー作成** (例: "Caret")
4. **キーをコピー** して安全に保管

### 対応モデル

Caret は Baseten Model APIs の最新モデルをサポートします。
最新価格: https://www.baseten.co/products/model-apis/
注: Kimi K2 0711 / Llama 4 Maverick / Llama 4 Scout は 10/8 5pm PT に廃止。
https://www.baseten.co/resources/changelog/model-api-deprecation-notice-kimi-k2-0711-scout-maverick/

- `zai-org/GLM-4.6` (Z AI) - 高度なエージェント/推論/コーディング (200k) \$0.60/\$2.20
- `moonshotai/Kimi-K2-Instruct-0905` (Moonshot AI) - 9月更新 (262K) \$0.60/\$2.50
- `openai/gpt-oss-120b` (OpenAI) - 120B MoE (128K) \$0.10/\$0.50
- `Qwen/Qwen3-Coder-480B-A35B-Instruct` - 高度なコーディング/推論 (262K) \$0.38/\$1.53
- `Qwen/Qwen3-235B-A22B-Instruct-2507` - 数学/推論特化 (262K) \$0.22/\$0.80
- `deepseek-ai/DeepSeek-R1` - 推論モデル (163K) \$2.55/\$5.95
- `deepseek-ai/DeepSeek-R1-0528` - 最新版 (163K) \$2.55/\$5.95
- `deepseek-ai/DeepSeek-V3.1` - ハイブリッド推論 (163K) \$0.50/\$1.50
- `deepseek-ai/DeepSeek-V3-0324` - 高速汎用 (163K) \$0.77/\$0.77

### Caret での設定

1. **Caret 設定を開く** (⚙️)
2. **Provider から Baseten を選択**
3. **API キーを入力**
4. **モデルを選択**

### プロダクション向けアーキテクチャ

#### 信頼性
- **99.99% uptime**
- **マルチクラウド自動スケール**
- **SOC 2 Type II / HIPAA 準拠**

#### パフォーマンス
- **事前最適化モデル**
- **最新 GPU**
- **超高速推論**

#### コスト効率
- **閉鎖型より 5〜10 倍安価**
- **効率的なマルチクラウド**
- **透明な価格**

#### DX
- **OpenAI 互換 API**
- **ドロップイン移行**
- **専用デプロイまで拡張可能**

### 特長

#### Function Calling / Tool Use
すべての Baseten モデルは構造化出力/関数呼び出し/ツール使用に対応します。

#### 推論能力
DeepSeek 系は段階的推論を提供します。

#### 長いコンテキスト
- **最大 100 万トークン** (Llama 4)
- **262K** (Qwen3)
- **163K** (DeepSeek)

#### 量子化最適化
fp4/fp8/fp16 を用いて性能と品質を両立。

### 移行

**OpenAI から:**
- `api.openai.com` → `inference.baseten.co/v1`

**他プロバイダーから:**
- OpenAI SDK フォーマットを利用

### ヒント

- **モデル選択:** 推論/コーディング/汎用に合わせて選択
- **コスト最適化:** 価格競争力が高い
- **コンテキスト:** 最大 1M トークン
- **Enterprise 対応**
- **動的モデル更新**
- **MCM**
- **サポート**

### 価格情報

最新価格は [Baseten Model APIs](https://www.baseten.co/products/model-apis/) を参照してください。
