---
title: "上下文窗口指南"
description: "理解并管理 AI 模型的上下文窗口"
---

## 什么是上下文窗口？

上下文窗口是 AI 模型一次可以处理的最大文本量。可以把它理解为模型的“工作内存”，决定了对话和代码中能同时参考多少内容。

<Note>
**要点：** 上下文窗口越大，可理解的代码库越多，但成本和响应时间也可能增加。
</Note>

## 上下文窗口大小

### 快速参考

| 大小 | 令牌 | 约等于单词数 | 使用场景 |
|------|--------|------------------|----------|
| **Small** | 8K-32K | 6,000-24,000 | 单文件、简单修改 |
| **Medium** | 128K | ~96,000 | 大多数项目 |
| **Large** | 200K | ~150,000 | 复杂代码库 |
| **Extra Large** | 400K+ | ~300,000+ | 全量应用 |
| **Massive** | 1M+ | ~750,000+ | 多项目分析 |

### 各模型上下文窗口

| 模型 | 上下文窗口 | 有效窗口* | 备注 |
|-------|---------------|------------------|-------|
| **Claude Sonnet 4.5** | 1M tokens | ~500K tokens | 大上下文下质量依旧出色 |
| **GPT-5** | 400K tokens | ~300K tokens | 三种模式导致性能波动 |
| **Gemini 2.5 Pro** | 1M+ tokens | ~600K tokens | 文档分析强 |
| **DeepSeek V3** | 128K tokens | ~100K tokens | 多数任务最优 |
| **Qwen3 Coder** | 256K tokens | ~200K tokens | 均衡型 |

*有效窗口指质量保持稳定的范围。

## 高效管理上下文

### 上下文包含的内容

1. **当前对话** - 所有聊天消息
2. **文件内容** - 你分享或 Caret 读取的文件
3. **工具输出** - 执行命令的结果
4. **系统提示词** - Caret 指令(占比很小)

### 优化策略

#### 1. 新功能从新任务开始
```
/new - 开始新任务以重置上下文
```

优势:
- 最大化可用上下文
- 去除无关历史
- 提升模型专注度

#### 2. 有策略地使用 @ 提及
不要一次塞入整个文件:
- `@filename.ts` 只包含需要的文件
- 大文件用搜索提取必要片段
- 按函数级别缩小引用范围

#### 3. 启用 auto-compact
Caret 可自动总结长对话:
- 设置 → Features → Auto-compact
- 保留重要上下文
- 减少令牌消耗

## 上下文上限警告

### 接近上限的迹象

| 迹象 | 含义 | 解决办法 |
|-------------|---------------|----------|
| **"Context window exceeded"** | 硬上限触发 | 开始新任务或启用 auto-compact |
| **响应变慢** | 上下文过载 | 缩减包含文件 |
| **重复建议** | 上下文碎片化 | 总结后开新任务 |
| **遗漏最新修改** | 上下文溢出 | 使用检查点 |

### 按项目规模的建议

#### 小型项目 (< 50 files)
- 多数模型即可
- 需要的文件可自由加入
- 无需特别优化

#### 中型项目 (50-500 files)
- 建议 128K+ 模型
- 只包含当前文件
- 以功能为单位整理上下文

#### 大型项目 (500+ files)
- 建议 200K+ 模型
- 以模块为单位聚焦
- 用搜索替代全量文件
- 拆分为多个阶段

## 高级上下文管理

### Plan/Act 模式优化

利用 Plan/Act 模式合理分配上下文:
- **Plan 模式**: 用低成本模型讨论
- **Act 模式**: 用高性能模型实现

示例:
```
Plan Mode: DeepSeek V3 (128K) - 低成本规划
Act Mode: Claude Sonnet 4.5 (1M) - 最大上下文实现
```

### 上下文裁剪策略

1. **Temporal Pruning**: 移除旧对话
2. **Semantic Pruning**: 移除无关代码
3. **Hierarchical Pruning**: 保留结构，裁掉细节

### 令牌计算提示

#### 大致估算
- **1 token ≈ 0.75 个单词**
- **1 token ≈ 4 个字符**
- **100 行代码 ≈ 500-1000 tokens**

#### 文件大小估算
| 文件类型 | 每 KB 令牌 |
|-----------|---------------|
| **代码** | ~250-400 |
| **JSON** | ~300-500 |
| **Markdown** | ~200-300 |
| **Plain text** | ~200-250 |

## 上下文窗口 FAQ

### Q: 为什么对话变长会降低质量？
**A:** 模型在过多上下文下会失去聚焦。有效窗口通常是最大值的 50-70%。

### Q: 使用最大上下文窗口总是更好吗？
**A:** 不一定。更大的上下文可能带来更高成本和质量下降，应按任务规模选择。

### Q: 如何查看上下文使用量？
**A:** Caret UI 会显示令牌使用情况，注意上下文是否接近上限。

### Q: 超过上限会发生什么？
**A:** Caret 可能：
- 自动压缩对话 (auto-compact)
- 给出错误并建议开启新任务
- 删除部分旧消息(带提示)

## 场景推荐

| 场景 | 推荐上下文 | 推荐模型 |
|----------|-------------------|------------------|
| **简单修改** | 32K-128K | DeepSeek V3 |
| **功能开发** | 128K-200K | Qwen3 Coder |
| **大型重构** | 400K+ | Claude Sonnet 4.5 |
| **代码评审** | 200K-400K | GPT-5 |
| **文档编写** | 128K | 低价模型 |
