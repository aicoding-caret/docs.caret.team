---
title: "Vercel AI Gateway"
description: "在 Careti 中使用 Vercel AI Gateway，通过一个端点访问 100 多个模型，具备路由、重试和支出可观察性。"
---

Vercel AI Gateway 为您提供一个 API 来访问来自多个提供商的模型。您只需通过模型 ID 切换，无需交换 SDK 或处理多个密钥。Careti 直接集成，因此您可以在下拉菜单中选择 Gateway 模型，像使用任何其他提供商一样使用它，并在流中查看 token 和缓存使用情况。

有用的链接：
- 团队仪表板：https://vercel.com/d?to=%2F%5Bteam%5D%2F%7E%2Fai
- 模型目录：https://vercel.com/ai-gateway/models
- 文档：https://vercel.com/docs/ai-gateway

## 您将获得什么

- 使用单个密钥访问 100 多个模型的一个端点
- 您在仪表板上配置的自动重试和回退
- 支出监控，包括按模型的请求、token 计数、缓存使用、延迟百分位数和成本
- OpenAI 兼容接口，现有客户端可直接使用

## 获取 API 密钥

1. 登录 https://vercel.com
2. 仪表板 → AI Gateway → API Keys → 创建密钥
3. 复制密钥

有关身份验证和 OIDC 选项的更多信息，请参阅 https://vercel.com/docs/ai-gateway/authentication

## 在 Careti 中配置

1. 打开 Careti 设置
2. 选择 **Vercel AI Gateway** 作为 API 提供商
3. 粘贴您的 Gateway API 密钥
4. 从列表中选择一个模型。Careti 会自动获取目录。您也可以粘贴确切的 ID

注意：
- 模型 ID 通常遵循 `provider/model` 格式。从目录复制确切的 ID
  示例：
  - `openai/gpt-5`
  - `anthropic/claude-sonnet-4`
  - `google/gemini-2.5-pro`
  - `groq/llama-3.1-70b`
  - `deepseek/deepseek-v3`

## 可操作的可观察性


  <img src="https://assets.vercel.com/image/upload/v1753121283/gateway-overhead-dark_zhqwwj.svg" alt="Vercel AI Gateway 可观察性，包括按模型的请求、tokens、缓存、延迟和成本。" />


需要关注的内容：
- 按模型的请求 - 确认路由和采用
- Tokens - 输入与输出，包括推理（如果暴露）
- 缓存 - 缓存输入和缓存创建 tokens
- 延迟 - p75 持续时间和 p75 首 token 时间
- 成本 - 按项目和按模型

用途：
- 在模型更改前后比较每个请求的输出 tokens
- 通过跟踪缓存读取和写入创建来验证缓存策略
- 在实验期间捕获 TTFT 回归
- 将预算与实际使用情况对齐

## 支持的模型

Gateway 支持大量且不断变化的模型集。Careti 从 Gateway API 拉取列表并在本地缓存。有关当前目录，请参阅 https://vercel.com/ai-gateway/models

## 提示

:::tip
每个环境（dev、staging、prod）使用单独的 Gateway 密钥。这可以保持仪表板清洁和预算隔离。
:::

:::note
定价是按提供商列表价格直通的。自带密钥没有加价。您仍需支付提供商和处理费用。
:::

<Info>
Vercel 不添加速率限制。上游提供商可能会。新账户每 30 天会收到 5 美元积分，直到首次付款。
</Info>

## 故障排除

- 401 - 将 Gateway 密钥发送到 Gateway 端点，而非上游 URL
- 404 模型 - 从 Vercel 目录复制确切的 ID
- 首 token 慢 - 检查仪表板中的 p75 TTFT，并尝试针对流式传输优化的模型
- 成本激增 - 在仪表板中按模型分解，并限制或路由流量

## 灵感

- 多模型评估 - 仅在 Careti 中交换模型 ID，并比较延迟和输出 tokens
- 渐进式推出 - 在仪表板中将小百分比路由到新模型，并根据指标增加
- 预算执行 - 设置按项目限制，无需更改代码

## 交叉链接

- OpenAI 兼容设置：/provider-config/openai-compatible
- 模型选择指南：/getting-started/model-selection-guide
- 理解上下文管理：/getting-started/understanding-context-management
