---
title: "OpenRouter"
description: "Learn how to use OpenRouter with Caret to access a wide variety of language models through a single API."
---

<Note>
캐럿(Caret) 기준 문서입니다. Caret v3.38.1 머지본을 따르며, 캐럿 전용 정책(허용/차단 모델, 지역 제한, 인증/라우팅)이 있을 경우 본문에서 `<Note>`로 표시합니다.
</Note>

<Note>
Provider Setup 강화: `caret-docs/features/f09-enhanced-provider-setup.md`에 따라 캐럿은 프로바이더 설정 검증/UX가 강화될 수 있습니다. 계정/조직 정책 또는 캐럿 라우터 적용 시 허용/차단 모델이 달라질 수 있음을 안내하세요.
</Note>

OpenRouter is an AI platform that provides access to a wide variety of language models from different providers, all through a single API. This can simplify setup and allow you to easily experiment with different models.

**Website:** [https://openrouter.ai/](https://openrouter.ai/)

### Getting an API Key

1.  **Sign Up/Sign In:** Go to the [OpenRouter website](https://openrouter.ai/). Sign in with your Google or GitHub account.
2.  **Get an API Key:** Go to the [keys page](https://openrouter.ai/keys). You should see an API key listed. If not, create a new key.
3.  **Copy the Key:** Copy the API key.

### Supported Models

OpenRouter supports a large and growing number of models. Caret automatically fetches the list of available models. Refer to the [OpenRouter Models page](https://openrouter.ai/models) for the complete and up-to-date list.

### Configuration in Caret

1.  **Open Caret Settings:** Click the settings icon (⚙️) in the Caret panel.
2.  **Select Provider:** Choose "OpenRouter" from the "API Provider" dropdown.
3.  **Enter API Key:** Paste your OpenRouter API key into the "OpenRouter API Key" field.
4.  **Select Model:** Choose your desired model from the "Model" dropdown.
5.  **(Optional) Custom Base URL:** If you need to use a custom base URL for the OpenRouter API, check "Use custom base URL" and enter the URL. Leave this blank for most users.

### Supported Transforms

OpenRouter provides an [optional "middle-out" message transform](https://openrouter.ai/docs/features/message-transforms) to help with prompts that exceed the maximum context size of a model. You can enable it by checking the "Compress prompts and message chains to the context size" box.

### Tips and Notes

-   **Model Selection:** OpenRouter offers a wide range of models. Experiment to find the best one for your needs.
-   **Pricing:** OpenRouter charges based on the underlying model's pricing. See the [OpenRouter Models page](https://openrouter.ai/models) for details.
-   **Prompt Caching:**
    -   OpenRouter passes caching requests to underlying models that support it. Check the [OpenRouter Models page](https://openrouter.ai/models) to see which models offer caching.
    -   For most models, caching should activate automatically if supported by the model itself (similar to how Requesty works).
    -   **Exception for Gemini Models via OpenRouter:** Due to potential response delays sometimes observed with Google's caching mechanism when accessed via OpenRouter, a manual activation step is required _specifically for Gemini models_.
    -   If using a **Gemini model** via OpenRouter, you **must manually check** the "Enable Prompt Caching" box in the provider settings to activate caching for that model. This checkbox serves as a temporary workaround. For non-Gemini models on OpenRouter, this checkbox is not necessary for caching.
