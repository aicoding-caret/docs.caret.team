---
title: "VS Code에서 LiteLLM 구성(멤버)"
sidebarTitle: "LiteLLM 구성(멤버)"
description: "관리자 설정 이후 VS Code에서 조직의 LiteLLM 프록시에 연결하는 방법"
---

팀 구성원은 로컬 개발 환경을 조직의 LiteLLM 프록시 설정에 연결할 수 있습니다. 관리자가 공급자 설정을 완료했으므로, **자격 증명만 추가**하면 됩니다.

## 시작 전 확인

LiteLLM 프록시에 연결하려면 아래가 필요합니다.

**Caret 확장 설치 및 조직 로그인**  
VS Code에 Caret 확장이 설치되어 있어야 하며, 조직 계정으로 로그인되어야 합니다. 아직 설치하지 않았다면 [설치 가이드](/ko/getting-started/installing-caret)를 참고하세요.

<Info>
**빠른 확인**: VS Code에서 Caret 패널을 열고, 좌측 하단에 조직 이름이 표시되면 로그인된 상태입니다.
</Info>

**LiteLLM 접근 자격 증명**  
조직의 LiteLLM 프록시에 접근할 수 있는 자격 증명이 필요합니다(API 키 또는 내부 네트워크 접근).

<Note>
필요한 자격 증명이 확실하지 않다면 관리자 또는 IT 팀에 문의하세요.
</Note>

## 구성 단계

<Steps>
<Step title="Caret 설정 열기">
VS Code에서 다음 중 하나로 설정 패널을 엽니다.

- Caret 패널의 설정 아이콘(⚙️) 클릭
- 채팅 영역 바로 아래의 API Provider 드롭다운 클릭(예: `LiteLLM` 또는 특정 모델)

</Step>

<Step title="LiteLLM 연결 구성">
조직의 프록시 구성 방식에 따라 설정이 달라집니다.

<AccordionGroup>
<Accordion title="API 키 인증">
조직이 API 키 인증을 사용하는 경우:

1. **LiteLLM** 공급자가 선택되어 있는지 확인
2. **API Key** 필드에 할당받은 키 입력
3. Base URL은 관리자 설정으로 자동 채워짐
4. **Save** 클릭

<Tip>
API 키는 VS Code 로컬에 저장되며 Caret 확장에서만 사용됩니다.
</Tip>
</Accordion>

<Accordion title="오픈 액세스(인증 없음)">
조직 내 네트워크에서 인증 없이 접근 가능한 경우:

1. **LiteLLM** 공급자 확인
2. API 키 필드를 비워둠
3. 확장이 구성된 프록시에 직접 연결
4. 추가 인증 불필요

<Info>
보안 네트워크 환경에서 내부 프록시를 사용할 때 흔한 구성입니다.
</Info>
</Accordion>

<Accordion title="커스텀 구성">
특수 인증이나 별도 파라미터가 필요한 경우:

1. 관리자 지침에 따라 추가 설정
2. 연결 문제 발생 시 IT 팀에 문의
3. VS Code 외부 설정이 필요할 수 있음

<Note>
일부 환경에서는 네트워크 설정이나 추가 인증이 필요할 수 있습니다.
</Note>
</Accordion>
</AccordionGroup>
</Step>

<Step title="모델 선택">
연결되면 조직의 LiteLLM 프록시에서 제공하는 모델 목록이 표시됩니다.

- 모델 드롭다운에서 사용 가능한 모델 확인
- 모델 목록은 조직의 프록시 구성에 따라 결정
- 작업 특성에 따라 모델 전환 가능
- 접근 권한에 따라 일부 모델이 제한될 수 있음

<Tip>
**모델 선택 가이드**
- **빠른 모델**: 단순 작업/응답 속도 우선
- **강력한 모델**: 복잡한 추론/리팩터링
- **특화 모델**: 코드 생성/특정 도메인
</Tip>
</Step>

<Step title="연결 테스트">
Caret에서 테스트 메시지를 보내 LiteLLM 연결이 정상인지 확인합니다.

<Tip>
**테스트 권장**
실제 개발 작업 전에 Plan 모드에서 연결을 먼저 확인하세요.
</Tip>
</Step>
</Steps>

## 모델 사용

### 사용 가능한 모델 범주
LiteLLM 프록시에서 제공하는 모델 예시:

**텍스트 생성 모델**
- OpenAI GPT-4, GPT-3.5 계열
- Anthropic Claude 3 Sonnet/Haiku/Opus
- 오픈 소스 Llama/Mistral

**코드 특화 모델**
- GPT-4 Code 계열
- CodeLlama
- 코드 보완 특화 모델

**멀티모달 모델**
- GPT-4 Vision
- Claude 3 Vision 모델

### 모델 선택 전략

- **빠른 반복**: 비용 효율 모델
- **복잡한 문제**: 고성능 모델
- **코드 집중**: 코드 특화 모델
- **시각 작업**: 멀티모달 모델

## 문제 해결

**LiteLLM 옵션이 보이지 않음**  
올바른 Caret 조직에 로그인되어 있는지 확인하세요. 관리자가 LiteLLM 구성을 저장했는지, 확장이 최신인지 점검하세요.

**연결 오류/타임아웃**  
프록시 엔드포인트에 접근 가능한지 확인하세요. 방화벽/VPN 요구 사항은 IT 팀에 문의하세요.

**인증 실패**  
API 키를 사용하는 경우 키가 올바르고 만료되지 않았는지 확인하세요. 관리자에게 키 상태를 확인하세요.

**모델이 제한되거나 보이지 않음**  
모델 목록은 프록시 구성에 따라 결정됩니다. 필요 모델이 없다면 관리자에게 요청하세요.

**응답 지연**  
모델/프록시 부하에 따라 응답이 느릴 수 있습니다. 일반 작업은 빠른 모델로 전환해보세요.

**특정 모델 오류**  
일부 모델이 일시적으로 비활성화될 수 있습니다. 다른 모델로 전환하거나 관리자에게 문의하세요.

## 보안 모범 사례

LiteLLM 프록시 사용 시 다음을 권장합니다.

- API 자격 증명 안전하게 보관
- 데이터 민감도에 맞는 모델 선택
- 조직의 사용 정책 준수
- 의심스러운 활동 즉시 보고
- Caret 확장 최신 상태 유지

조직 관리자가 허용한 모델과 정책만 적용됩니다. 모델 목록은 프록시 구성 및 권한에 따라 자동 반영됩니다.
