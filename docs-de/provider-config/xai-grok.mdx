---
title: "xAI (Grok)"
description: "Erfahren Sie, wie Sie die Grok-Modelle von xAI mit Careti konfigurieren und verwenden, einschließlich API-Key-Einrichtung, unterstützten Modellen und Reasoning-Funktionen."
---

xAI ist das Unternehmen hinter Grok, einem Large Language Model, das für seine Konversationsfähigkeiten und sein großes Context Window bekannt ist. Grok-Modelle sind darauf ausgelegt, hilfreiche, informative und kontextuell relevante Antworten zu liefern.

**Website:** [https://x.ai/](https://x.ai/)

### Getting an API Key

1.  **Anmelden/Registrieren:** Rufen Sie die [xAI Console](https://console.x.ai/) auf. Erstellen Sie ein Konto oder melden Sie sich an.
2.  **Zu API-Keys navigieren:** Gehen Sie zum Bereich API-Keys in Ihrem Dashboard.
3.  **Key erstellen:** Klicken Sie hier, um einen neuen API-Key zu erstellen. Geben Sie Ihrem Key einen aussagekräftigen Namen (z. B. „Careti“).
4.  **Key kopieren:** **Wichtig:** Kopieren Sie den API-Key _sofort_. Sie können ihn später nicht mehr einsehen. Bewahren Sie ihn sicher auf.

### Supported Models

Careti unterstützt die folgenden xAI Grok-Modelle:

#### Grok-3 Models

-   `grok-3-beta` (Default) – xAIs Grok-3 Beta-Modell mit 131K Context Window
-   `grok-3-fast-beta` – xAIs Grok-3 Fast Beta-Modell mit 131K Context Window
-   `grok-3-mini-beta` – xAIs Grok-3 Mini Beta-Modell mit 131K Context Window
-   `grok-3-mini-fast-beta` – xAIs Grok-3 Mini Fast Beta-Modell mit 131K Context Window

#### Grok-2 Models

-   `grok-2-latest` – xAIs Grok-2 Modell – neueste Version mit 131K Context Window
-   `grok-2` – xAIs Grok-2 Modell mit 131K Context Window
-   `grok-2-1212` – xAIs Grok-2 Modell (Version 1212) mit 131K Context Window

#### Grok Vision Models

-   `grok-2-vision-latest` – xAIs Grok-2 Vision Modell – neueste Version mit Bildunterstützung und 32K Context Window
-   `grok-2-vision` – xAIs Grok-2 Vision Modell mit Bildunterstützung und 32K Context Window
-   `grok-2-vision-1212` – xAIs Grok-2 Vision Modell (Version 1212) mit Bildunterstützung und 32K Context Window
-   `grok-vision-beta` – xAIs Grok Vision Beta-Modell mit Bildunterstützung und 8K Context Window

#### Legacy Models

-   `grok-beta` – xAIs Grok Beta-Modell (Legacy) mit 131K Context Window

### Configuration in Careti

1.  **Careti-Einstellungen öffnen:** Klicken Sie auf das Einstellungs-Icon (⚙️) im Careti-Panel.
2.  **Provider auswählen:** Wählen Sie „xAI“ aus dem „API Provider“-Dropdown-Menü.
3.  **API-Key eingeben:** Fügen Sie Ihren xAI API-Key in das Feld „xAI API Key“ ein.
4.  **Modell auswählen:** Wählen Sie Ihr gewünschtes Grok-Modell aus dem „Model“-Dropdown-Menü.

### Reasoning Capabilities

Grok 3 Mini-Modelle verfügen über spezialisierte Reasoning-Funktionen, die es ihnen ermöglichen, „vor der Antwort nachzudenken“ – besonders nützlich für komplexe Problemlösungsaufgaben.

#### Reasoning-Enabled Models

Reasoning wird nur unterstützt von:

-   `grok-3-mini-beta`
-   `grok-3-mini-fast-beta`

Die Grok 3-Modelle `grok-3-beta` und `grok-3-fast-beta` unterstützen kein Reasoning.

#### Controlling Reasoning Effort

Bei der Verwendung von Reasoning-fähigen Modellen können Sie mit dem Parameter `reasoning_effort` steuern, wie intensiv das Modell nachdenkt:

-   `low`: Minimale Bedenkzeit, verbraucht weniger Tokens für schnelle Antworten
-   `high`: Maximale Bedenkzeit, nutzt mehr Tokens für komplexe Probleme

Wählen Sie `low` für einfache Abfragen, die schnell abgeschlossen werden sollen, und `high` für schwierigere Probleme, bei denen die Antwortlatenz weniger wichtig ist.

#### Key Features

-   **Schritt-für-Schritt-Problemlösung**: Das Modell durchdenkt Probleme methodisch, bevor es eine Antwort liefert
-   **Stärke in Mathematik & Quantitativen Aufgaben**: Hervorragend bei numerischen Herausforderungen und Logikrätseln
-   **Zugriff auf Reasoning-Trace**: Der Denkprozess des Modells ist über das Feld `reasoning_content` im Response Completion Object verfügbar

### Tips and Notes

-   **Context Window:** Die meisten Grok-Modelle verfügen über große Context Windows (bis zu 131K Tokens), sodass Sie umfangreiche Mengen an Code und Kontext in Ihre Prompts aufnehmen können.
-   **Vision-Fähigkeiten:** Wählen Sie Vision-fähige Modelle (`grok-2-vision-latest`, `grok-2-vision` usw.), wenn Sie Bilder verarbeiten oder analysieren müssen.
-   **Preise:** Die Preise variieren je nach Modell, wobei die Input-Kosten zwischen 0,3 $ und 5,0 $ pro Million Tokens und die Output-Kosten zwischen 0,5 $ und 25,0 $ pro Million Tokens liegen. Weitere Informationen zu den aktuellen Preisen finden Sie in der xAI-Dokumentation.
-   **Leistungsabwägungen:** „Fast“-Varianten bieten in der Regel schnellere Antwortzeiten, können aber höhere Kosten verursachen, während „Mini“-Varianten wirtschaftlicher sind, aber möglicherweise einen geringeren Funktionsumfang haben.